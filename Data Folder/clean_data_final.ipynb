{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c43112b9-977c-421d-8b0d-d9d9d738d170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82c87e7-e59d-4d42-b0c0-e972f5458e05",
   "metadata": {},
   "source": [
    "# Merge all flight data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b98705dc-28f6-41d4-a556-9e8b459357d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_start_year = 2010\n",
    "cf_end_year = 2023\n",
    "cf_year_range = [y for y in range(cf_start_year, cf_end_year+1) if y != 2020]\n",
    "\n",
    "cf_path_folder = \"full_historical_data_bf2024\"\n",
    "cf_path_list = [cf_path_folder + \n",
    "                \"/On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_\" + \n",
    "                f\"{j}\" + \"_\" + f\"{i}\" + \".csv\" for i in range(1,13) for j in cf_year_range]\n",
    "\n",
    "cf_start = datetime(cf_start_year, 1, 1)\n",
    "cf_end = datetime(cf_end_year, 12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fe75e86-7cde-4b48-98a3-f9e5c1a68571",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (76,77,84,85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84,85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,69,76,77,84,85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,69,76,77,84,85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84,85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84,85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84,85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (69,76,77,84,85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84,85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84,85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84,85,92) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (76,77,84,85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (77,84,85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (76,77,84,85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,69,76,77,84,85,92) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (48,69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_9132\\3286583175.py:4: DtypeWarning: Columns (69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "# gets all files and puts them into a dict\n",
    "df_dict = {}\n",
    "for i, file_path in enumerate(cf_path_list):\n",
    "    df_dict[f\"df_{i+1}\"] = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dff4a796-84fc-46c9-a179-9e863b962938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82133464\n",
      "Index(['Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek', 'FlightDate',\n",
      "       'Reporting_Airline', 'DOT_ID_Reporting_Airline',\n",
      "       'IATA_CODE_Reporting_Airline', 'Tail_Number',\n",
      "       ...\n",
      "       'Div4TailNum', 'Div5Airport', 'Div5AirportID', 'Div5AirportSeqID',\n",
      "       'Div5WheelsOn', 'Div5TotalGTime', 'Div5LongestGTime', 'Div5WheelsOff',\n",
      "       'Div5TailNum', 'Unnamed: 109'],\n",
      "      dtype='object', length=110)\n"
     ]
    }
   ],
   "source": [
    "print(sum(len(df) for df in df_dict.values()))\n",
    "print(df_dict['df_1'].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a889cc5-2938-4846-9c13-1a035687c87b",
   "metadata": {},
   "source": [
    "## Configure columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1ee5bd7-0946-4c9b-9afb-7949cf035360",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['FlightDate', 'OriginAirportID', 'DestAirportID', 'CRSDepTime', 'WeatherDelay', 'Cancelled', 'CancellationCode', 'Reporting_Airline']\n",
    "\n",
    "df_test = pd.concat([df[columns_to_keep] for df in df_dict.values()], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bb684a-afef-4832-ae45-fbe019558141",
   "metadata": {},
   "source": [
    "### Reduce memory of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d139857-4210-4e1c-a182-7a8eca0ab732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlightDate            object\n",
       "OriginAirportID        int64\n",
       "DestAirportID          int64\n",
       "CRSDepTime           float64\n",
       "WeatherDelay         float64\n",
       "Cancelled            float64\n",
       "CancellationCode      object\n",
       "Reporting_Airline     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb95342f-534e-4385-a326-c7f15c040c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Cancelled to bool\n",
    "df_test['Cancelled'] = df_test['Cancelled'].astype('boolean')\n",
    "# Downcast floats to float32\n",
    "float_cols = ['CRSDepTime', 'WeatherDelay', 'CancelledWeather']\n",
    "for col in float_cols:\n",
    "    if col in df_test.columns:\n",
    "        df_test[col] = pd.to_numeric(df_test[col], downcast='float')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3076175-df5e-4f69-a038-b13648d9c991",
   "metadata": {},
   "source": [
    "### Add Cancelled due to Weather column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e80d72f8-5c91-4ecf-81df-217d952492d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"CancelledWeather\"] = df_test[\"Cancelled\"].where(df_test[\"CancellationCode\"] == \"B\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21bad57-e48b-472b-a3c8-bd51fc936139",
   "metadata": {},
   "source": [
    "### Merge with lookup tables to get standard airport codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b938c18-0b6c-4a15-bf76-5559423ddb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lookup tables for airport_id and airport codes\n",
    "airport_ids = pd.read_csv('misc/L_AIRPORT_ID.csv')\n",
    "airport_codes = pd.read_csv('misc/L_AIRPORT_CODES.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3c41792-89b0-40fd-8918-7ee846afff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Map airport ID -> Name\n",
    "id_to_name = dict(zip(airport_ids['Code'], airport_ids['Description']))\n",
    "\n",
    "# Step 2: Map Name -> Code\n",
    "name_to_code = dict(zip(airport_codes['Description'], airport_codes['Code']))\n",
    "\n",
    "# Step 3: Apply both mappings\n",
    "df_test['Origin_Airport'] = df_test['OriginAirportID'].map(id_to_name).map(name_to_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9f2e925-51b1-432f-961a-0e8f15235d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(columns=['OriginAirportID', 'DestAirportID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ce7bf9-91c4-4325-8492-e5e002331e38",
   "metadata": {},
   "source": [
    "### Format time data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c027c73a-29ef-4d77-b626-606e9f7f6fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FlightDate</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>WeatherDelay</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>CancellationCode</th>\n",
       "      <th>Reporting_Airline</th>\n",
       "      <th>CancelledWeather</th>\n",
       "      <th>Origin_Airport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-09</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9E</td>\n",
       "      <td>False</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-16</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9E</td>\n",
       "      <td>False</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-23</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9E</td>\n",
       "      <td>False</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-30</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9E</td>\n",
       "      <td>False</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9E</td>\n",
       "      <td>False</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FlightDate  CRSDepTime  WeatherDelay  Cancelled CancellationCode  \\\n",
       "0  2010-01-09      1056.0           0.0      False              NaN   \n",
       "1  2010-01-16      1056.0           0.0      False              NaN   \n",
       "2  2010-01-23      1056.0           NaN      False              NaN   \n",
       "3  2010-01-30      1056.0           NaN      False              NaN   \n",
       "4  2010-01-05      1755.0           NaN      False              NaN   \n",
       "\n",
       "  Reporting_Airline  CancelledWeather Origin_Airport  \n",
       "0                9E             False            ATL  \n",
       "1                9E             False            ATL  \n",
       "2                9E             False            ATL  \n",
       "3                9E             False            ATL  \n",
       "4                9E             False            ATL  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5779594e-0bc8-4ee1-8148-0aba4832542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['date'] = pd.to_datetime(df_test['FlightDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e4f0d7f-da67-46d8-b4ed-dc19848492e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one row has an NaN value\n",
    "df_test = df_test.dropna(subset=[\"CRSDepTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb64e2f9-da27-4b8e-9187-83a5f513b9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FlightDate</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>WeatherDelay</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>CancellationCode</th>\n",
       "      <th>Reporting_Airline</th>\n",
       "      <th>CancelledWeather</th>\n",
       "      <th>Origin_Airport</th>\n",
       "      <th>date</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-09</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9E</td>\n",
       "      <td>False</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2010-01-09</td>\n",
       "      <td>2010-01-09 10:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-16</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9E</td>\n",
       "      <td>False</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2010-01-16</td>\n",
       "      <td>2010-01-16 10:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-23</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9E</td>\n",
       "      <td>False</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2010-01-23</td>\n",
       "      <td>2010-01-23 10:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-30</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9E</td>\n",
       "      <td>False</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2010-01-30</td>\n",
       "      <td>2010-01-30 10:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9E</td>\n",
       "      <td>False</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>2010-01-05 17:55:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FlightDate  CRSDepTime  WeatherDelay  Cancelled CancellationCode  \\\n",
       "0  2010-01-09      1056.0           0.0      False              NaN   \n",
       "1  2010-01-16      1056.0           0.0      False              NaN   \n",
       "2  2010-01-23      1056.0           NaN      False              NaN   \n",
       "3  2010-01-30      1056.0           NaN      False              NaN   \n",
       "4  2010-01-05      1755.0           NaN      False              NaN   \n",
       "\n",
       "  Reporting_Airline  CancelledWeather Origin_Airport       date  \\\n",
       "0                9E             False            ATL 2010-01-09   \n",
       "1                9E             False            ATL 2010-01-16   \n",
       "2                9E             False            ATL 2010-01-23   \n",
       "3                9E             False            ATL 2010-01-30   \n",
       "4                9E             False            ATL 2010-01-05   \n",
       "\n",
       "             datetime  \n",
       "0 2010-01-09 10:56:00  \n",
       "1 2010-01-16 10:56:00  \n",
       "2 2010-01-23 10:56:00  \n",
       "3 2010-01-30 10:56:00  \n",
       "4 2010-01-05 17:55:00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad time with zeros, then combine into one datetime column\n",
    "# NOTE: CRSDepTime is local time\n",
    "df_test[\"datetime\"] = df_test[\"date\"] + pd.to_timedelta(\n",
    "    df_test[\"CRSDepTime\"].apply(lambda x: int(x // 100) * 60 + int(x % 100)), unit=\"m\"\n",
    ")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b43e0d5-ac88-4c80-8418-ed5f8d0a6460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FlightDate</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>WeatherDelay</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>CancellationCode</th>\n",
       "      <th>Reporting_Airline</th>\n",
       "      <th>CancelledWeather</th>\n",
       "      <th>Origin_Airport</th>\n",
       "      <th>date</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-09</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9E</td>\n",
       "      <td>False</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2010-01-09</td>\n",
       "      <td>2010-01-09 10:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-16</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9E</td>\n",
       "      <td>False</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2010-01-16</td>\n",
       "      <td>2010-01-16 10:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-23</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9E</td>\n",
       "      <td>False</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2010-01-23</td>\n",
       "      <td>2010-01-23 10:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-30</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9E</td>\n",
       "      <td>False</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2010-01-30</td>\n",
       "      <td>2010-01-30 10:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9E</td>\n",
       "      <td>False</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>2010-01-05 17:55:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FlightDate  CRSDepTime  WeatherDelay  Cancelled CancellationCode  \\\n",
       "0  2010-01-09      1056.0           0.0      False              NaN   \n",
       "1  2010-01-16      1056.0           0.0      False              NaN   \n",
       "2  2010-01-23      1056.0           0.0      False              NaN   \n",
       "3  2010-01-30      1056.0           0.0      False              NaN   \n",
       "4  2010-01-05      1755.0           0.0      False              NaN   \n",
       "\n",
       "  Reporting_Airline  CancelledWeather Origin_Airport       date  \\\n",
       "0                9E             False            ATL 2010-01-09   \n",
       "1                9E             False            ATL 2010-01-16   \n",
       "2                9E             False            ATL 2010-01-23   \n",
       "3                9E             False            ATL 2010-01-30   \n",
       "4                9E             False            ATL 2010-01-05   \n",
       "\n",
       "             datetime  \n",
       "0 2010-01-09 10:56:00  \n",
       "1 2010-01-16 10:56:00  \n",
       "2 2010-01-23 10:56:00  \n",
       "3 2010-01-30 10:56:00  \n",
       "4 2010-01-05 17:55:00  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['WeatherDelay'] = df_test['WeatherDelay'].fillna(0)\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478c8629-1a7a-4941-928e-5a428de04a09",
   "metadata": {},
   "source": [
    "# Filter by Airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ed83a9c-c908-4239-974d-3b559834252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = [\n",
    "    \"ATL\", \"ORD\", \"JFK\", \"LGA\", \"LAX\",\n",
    "    \"SFO\", \"IAH\", \"HOU\", \"DEN\", \"MCO\",\n",
    "    \"MIA\", \"LAS\", \"IAD\", \"PHX\", \"SEA\",\n",
    "    \"BOS\", \"CLT\", \"ANC\", \"PDX\",\n",
    "    \n",
    "    \"MSP\", \"SLC\", \"BOI\", \"JAC\", \"FSD\",\n",
    "    \"STL\", \"BZN\", \"ABQ\", \"OKC\", \"DSM\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c51a71e-b8fb-486a-822d-0203b5a3f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[df_test['Origin_Airport'].isin(airports)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61be50bf-8c07-488a-99a9-b2ed5957f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['datetime'] = pd.to_datetime(df_test['datetime'], errors='coerce', unit='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ac61862-5030-4cb7-8f47-465bc8de50b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.sort_values(by=[\"Origin_Airport\", \"datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "276edd0a-b301-42da-9255-e6320c78548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"final_extra_airports_2010_to_2023.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7e051a-e95b-4b59-8e89-32f220c186f2",
   "metadata": {},
   "source": [
    "# Get Weather Data in separate df\n",
    "### Get snapshots at 2-hour intervals at all airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0420bdb-e0cb-4f27-90d3-aecc1612a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from meteostat import Stations, Daily, Point, Hourly\n",
    "import pandas as pd\n",
    "\n",
    "stations = Stations()\n",
    "\n",
    "all_stations = stations.region('US').fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "251d497a-568e-4554-b2f6-70f758c7d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = [\n",
    "    \"ATL\", \"ORD\", \"JFK\", \"LGA\", \"LAX\",\n",
    "    \"SFO\", \"IAH\", \"HOU\", \"DEN\", \"MCO\",\n",
    "    \"MIA\", \"LAS\", \"IAD\", \"PHX\", \"SEA\",\n",
    "    \"BOS\", \"CLT\", \"ANC\", \"PDX\",\n",
    "    \n",
    "    \"MSP\", \"SLC\", \"BOI\", \"JAC\", \"FSD\",\n",
    "    \"STL\", \"BZN\", \"ABQ\", \"OKC\", \"DSM\"\n",
    "]\n",
    "\n",
    "cf_start = pd.to_datetime('2010-1-1')\n",
    "cf_end = pd.to_datetime('2023-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4453d5b-0ef3-4943-811e-0a0c234da2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Cannot load hourly/2010/KCVC0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2011/KCVC0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2012/KCVC0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2013/KCVC0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2014/KCVC0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2015/KCVC0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2016/KCVC0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2017/KCVC0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2018/KCVC0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2019/KCVC0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATL complete, 61345 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Cannot load hourly/2010/N5DTT.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2011/N5DTT.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2012/N5DTT.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2013/N5DTT.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2014/N5DTT.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2015/N5DTT.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2016/N5DTT.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2017/N5DTT.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2018/N5DTT.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2019/N5DTT.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2020/N5DTT.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2021/N5DTT.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORD complete, 61345 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Cannot load hourly/2010/KJRB0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2011/KJRB0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2012/KJRB0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2013/KJRB0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2014/KJRB0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2015/KJRB0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2011/KNYC0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2012/KNYC0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2013/KNYC0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2014/KNYC0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2015/KNYC0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2016/KNYC0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2017/KNYC0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2018/KNYC0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2019/KNYC0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JFK complete, 61345 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Cannot load hourly/2011/72505.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2012/72505.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2013/72505.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2014/72505.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2015/72505.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2016/72505.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGA complete, 61345 rows\n",
      "LAX complete, 61345 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RuntimeWarning: divide by zero encountered in log\n",
      "Warning: Cannot load hourly/2011/72585.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2012/72585.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2013/72585.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2014/72585.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2015/72585.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2016/72585.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFO complete, 61345 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Cannot load hourly/2010/877AW.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2011/877AW.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2012/877AW.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2013/877AW.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2014/877AW.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2015/877AW.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2016/877AW.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2017/877AW.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2018/877AW.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2019/877AW.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2020/877AW.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2021/877AW.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IAH complete, 61345 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Cannot load hourly/2010/SC9N0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2011/SC9N0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2012/SC9N0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2013/SC9N0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2014/SC9N0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2015/SC9N0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2016/SC9N0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2017/SC9N0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2018/SC9N0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2019/SC9N0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2020/SC9N0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2021/SC9N0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOU complete, 61344 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Cannot load hourly/2013/72565.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2010/72469.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2011/72469.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2012/72469.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2013/72469.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2014/72469.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2015/72469.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2016/72469.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2017/72469.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEN complete, 61345 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RuntimeWarning: divide by zero encountered in log\n",
      "RuntimeWarning: divide by zero encountered in log\n",
      "RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCO complete, 61345 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Cannot load hourly/2010/JY84X.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2011/JY84X.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2012/JY84X.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2013/JY84X.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2014/JY84X.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2015/JY84X.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2016/JY84X.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2017/JY84X.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2018/JY84X.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2019/JY84X.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2020/JY84X.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2021/JY84X.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIA complete, 61345 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAS complete, 61345 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Cannot load hourly/2010/TOFHW.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2011/TOFHW.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2012/TOFHW.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2013/TOFHW.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2014/TOFHW.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2015/TOFHW.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2016/TOFHW.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2017/TOFHW.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2018/TOFHW.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2019/TOFHW.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2020/TOFHW.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2021/TOFHW.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IAD complete, 61345 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RuntimeWarning: divide by zero encountered in log\n",
      "RuntimeWarning: divide by zero encountered in log\n",
      "RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHX complete, 61345 rows\n",
      "SEA complete, 61345 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Cannot load hourly/2010/74492.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2011/74492.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2012/74492.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2013/74492.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2014/74492.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2015/74492.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2016/74492.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2017/74492.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2018/74492.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2019/74492.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2020/74492.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOS complete, 61345 rows\n",
      "CLT complete, 61345 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Cannot load hourly/2010/70270.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2011/70270.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2012/70270.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANC complete, 61345 rows\n",
      "PDX complete, 61345 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Cannot load hourly/2010/TIH4U.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2011/TIH4U.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2012/TIH4U.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2013/TIH4U.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2014/TIH4U.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2015/TIH4U.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2016/TIH4U.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2017/TIH4U.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2018/TIH4U.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2019/TIH4U.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2020/TIH4U.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2021/TIH4U.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSP complete, 61345 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Cannot load hourly/2010/KU420.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2011/KU420.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2012/KU420.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2013/KU420.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2014/KU420.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2015/KU420.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLC complete, 61345 rows\n",
      "BOI complete, 61345 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RuntimeWarning: divide by zero encountered in log\n",
      "Warning: Cannot load hourly/2014/KDIJ0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAC complete, 61345 rows\n",
      "FSD complete, 61345 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Cannot load hourly/2010/4P0GT.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2011/4P0GT.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2012/4P0GT.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2013/4P0GT.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2014/4P0GT.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2015/4P0GT.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2016/4P0GT.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2017/4P0GT.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2018/4P0GT.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2019/4P0GT.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2020/4P0GT.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2021/4P0GT.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STL complete, 61345 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Cannot load hourly/2014/KBZN0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BZN complete, 61345 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Cannot load hourly/2011/KZAB0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2012/KZAB0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2013/KZAB0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2014/KZAB0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2015/KZAB0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2016/KZAB0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2017/KZAB0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2018/KZAB0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2019/KZAB0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2020/KZAB0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2021/KZAB0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2022/KZAB0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "Warning: Cannot load hourly/2023/KZAB0.csv.gz from https://data.meteostat.net/\n",
      "FutureWarning: <class 'pandas.core.arrays.string_.StringArray'>._reduce will require a `keepdims` parameter in the future\n",
      "RuntimeWarning: divide by zero encountered in log\n",
      "RuntimeWarning: divide by zero encountered in log\n",
      "RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABQ complete, 61345 rows\n",
      "OKC complete, 61345 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSM complete, 61345 rows\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Find a Meteostat station for an IATA code.\"\"\"\n",
    "def find_station_for_code(df_stations, code):\n",
    "    if 'iata' in df_stations.columns:\n",
    "        s = df_stations[df_stations['iata'] == code]\n",
    "        if not s.empty:\n",
    "            return s.iloc[0]\n",
    "    if 'icao' in df_stations.columns:\n",
    "        # exception: ANC is PANC \n",
    "        if (code == \"ANC\"):\n",
    "            s = df_stations[df_stations['icao'] == f\"P{code}\"]\n",
    "        else:\n",
    "            s = df_stations[df_stations['icao'] == f\"K{code}\"]\n",
    "        if not s.empty:\n",
    "            return s.iloc[0]\n",
    "        s = df_stations[df_stations['icao'] == code]\n",
    "        if not s.empty:\n",
    "            return s.iloc[0]\n",
    "    return None\n",
    "\n",
    "weather_snapshots = []\n",
    "\n",
    "for airport in airports:\n",
    "    try:\n",
    "        st = find_station_for_code(all_stations, airport)\n",
    "        if st is None:\n",
    "            print(f\"No station found for {airport}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        loc = Point(st['latitude'], st['longitude'], st['elevation'])\n",
    "\n",
    "        # Fetch hourly data\n",
    "        data = Hourly(loc, cf_start, cf_end).fetch()\n",
    "\n",
    "        if data.empty:\n",
    "            print(f\"No weather data for {airport}.\")\n",
    "            continue\n",
    "\n",
    "        # Convert to DataFrame with datetime\n",
    "        data.reset_index(inplace=True)\n",
    "        data['Origin_Airport'] = airport\n",
    "\n",
    "        # Keep exact 2-hour snapshots (no averaging)\n",
    "        data['time'] = pd.to_datetime(data['time'])\n",
    "        data = data.set_index('time')\n",
    "        \n",
    "        # Keep only rows at exact 2-hour timestamps\n",
    "        data = data[data.index.minute == 0]          # ensure on-the-hour\n",
    "        data = data[data.index.hour % 2 == 0]        # every 2 hours (0, 2, 4, 6...)\n",
    "        \n",
    "        data = data.reset_index()\n",
    "\n",
    "        # Rename for clarity\n",
    "        data.rename(columns={\n",
    "            'time': 'datetime',\n",
    "            'temp': 'temperature_C',\n",
    "            'dwpt': 'dew_point_C',\n",
    "            'rhum': 'humidity_percent',\n",
    "            'prcp': 'precipitation_mm',\n",
    "            # 'snow': 'snowfall_mm',\n",
    "            'wdir': 'wind_direction_deg',\n",
    "            'wspd': 'wind_speed_kmh',\n",
    "            'wpgt': 'wind_gust_kmh',\n",
    "            'pres': 'pressure_hPa',\n",
    "            'tsun': 'sunshine_minutes',\n",
    "            'coco': 'weather_code'\n",
    "        }, inplace=True)\n",
    "\n",
    "        weather_snapshots.append(data)\n",
    "        print(f\"{airport} complete, {len(data)} rows\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"=Error for {airport}: {e}\")\n",
    "\n",
    "# Combine all airports into one DataFrame\n",
    "weather_all = pd.concat(weather_snapshots, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea107420-e1fa-4c77-a2bd-65c7df53a9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>temperature_C</th>\n",
       "      <th>dew_point_C</th>\n",
       "      <th>humidity_percent</th>\n",
       "      <th>precipitation_mm</th>\n",
       "      <th>snow</th>\n",
       "      <th>wind_direction_deg</th>\n",
       "      <th>wind_speed_kmh</th>\n",
       "      <th>wind_gust_kmh</th>\n",
       "      <th>pressure_hPa</th>\n",
       "      <th>sunshine_minutes</th>\n",
       "      <th>weather_code</th>\n",
       "      <th>Origin_Airport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01 00:00:00</td>\n",
       "      <td>7.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>97.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>290.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1018.9</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-01 02:00:00</td>\n",
       "      <td>7.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>280.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1019.6</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-01 04:00:00</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>270.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-01 06:00:00</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>270.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1019.1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-01 08:00:00</td>\n",
       "      <td>6.7</td>\n",
       "      <td>5.6</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>330.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1018.8</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  temperature_C  dew_point_C  humidity_percent  \\\n",
       "0 2010-01-01 00:00:00            7.2          6.8              97.0   \n",
       "1 2010-01-01 02:00:00            7.2          6.8              97.0   \n",
       "2 2010-01-01 04:00:00            6.7          6.7             100.0   \n",
       "3 2010-01-01 06:00:00            6.7          6.7             100.0   \n",
       "4 2010-01-01 08:00:00            6.7          5.6              93.0   \n",
       "\n",
       "   precipitation_mm  snow  wind_direction_deg  wind_speed_kmh  wind_gust_kmh  \\\n",
       "0              <NA>  <NA>               290.0             5.4           <NA>   \n",
       "1               0.0  <NA>               280.0             7.6           <NA>   \n",
       "2               0.0  <NA>               270.0             5.4           <NA>   \n",
       "3               0.0  <NA>               270.0             7.6           <NA>   \n",
       "4               0.0  <NA>               330.0            16.6           <NA>   \n",
       "\n",
       "   pressure_hPa  sunshine_minutes  weather_code Origin_Airport  \n",
       "0        1018.9              <NA>          <NA>            ATL  \n",
       "1        1019.6              <NA>          <NA>            ATL  \n",
       "2        1019.5              <NA>          <NA>            ATL  \n",
       "3        1019.1              <NA>          <NA>            ATL  \n",
       "4        1018.8              <NA>          <NA>            ATL  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9dd1b83-59f2-408f-be6f-cdff786ae97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'temperature_C', 'dew_point_C', 'humidity_percent',\n",
       "       'precipitation_mm', 'snow', 'wind_direction_deg', 'wind_speed_kmh',\n",
       "       'wind_gust_kmh', 'pressure_hPa', 'sunshine_minutes', 'weather_code',\n",
       "       'Origin_Airport'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb482ccd-20df-40b3-aa9d-ca03519926e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_all.to_csv(\"weather_extra_airports_2010_to_2023.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
