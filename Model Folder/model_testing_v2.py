# -*- coding: utf-8 -*-
"""Model_Testing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JojYPsDOAQQvtQoMe8-l9D1YP5y5c6Dy
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

df = pd.read_csv('/content/drive/MyDrive/Weather Data Project (Southwest Airlines)/final_version_dataset')

import pandas as pd


group_cols = ['FlightDate', 'Origin_Airport']  #

weather_cols = [
    'temperature_C', 'dew_point_C', 'humidity_percent', 'precipitation_mm',
    'wind_direction_deg', 'wind_speed_kmh', 'pressure_hPa',
    'snow_mm'
]

for col in weather_cols:
    df[col] = df.groupby(group_cols)[col].transform(lambda x: x.fillna(x.mean()))


df[weather_cols] = df[weather_cols].fillna(df[weather_cols].mean())

print(df.isnull().sum())

df = df.drop(columns=['wind_gust_kmh','weather_code', 'CancellationCode'])

"""## HistGradient"""

def compute_disruption(row):

    if pd.isna(row['CancelledWeather']) or pd.isna(row['WeatherDelay']):
        return 0
    elif row['CancelledWeather'] == 1:
        return 100
    elif row['WeatherDelay'] > 30:
        return 75
    elif row['WeatherDelay'] > 0:
        return 25
    else:
        return 0

df['disruption_score'] = df.apply(compute_disruption, axis=1)

import pandas as pd
from sklearn.ensemble import HistGradientBoostingRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler


features = [
    'temperature_C', 'dew_point_C', 'humidity_percent', 'precipitation_mm',
    'wind_direction_deg', 'wind_speed_kmh', 'pressure_hPa',
    'snow_mm'
]
X = df[features]
y = df['disruption_score']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = HistGradientBoostingRegressor()
model.fit(X_train, y_train)


y_pred = model.predict(X_test)

scaler = MinMaxScaler(feature_range=(0, 100))
y_pred_scaled = scaler.fit_transform(y_pred.reshape(-1, 1)).flatten()


result = X_test.copy()
result['predicted_weather_score'] = y_pred_scaled
print(result[['predicted_weather_score']].head())

import matplotlib.pyplot as plt


plt.hist(result['predicted_weather_score'], bins=30, color='skyblue', edgecolor='black')
plt.xlabel('Predicted Weather Disruption Score')
plt.ylabel('Frequency')
plt.title('Distribution of Weather Disruption Scores')
plt.show()

"""## Neural Network"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.callbacks import EarlyStopping

scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

model = Sequential([
    Dense(64, input_dim=X_scaled.shape[1], activation='relu'),
    Dropout(0.2),
    Dense(64, activation='relu'),
    Dropout(0.2),
    Dense(1, activation='linear')
])

model.compile(optimizer='adam', loss='mse')

early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
model.fit(X_scaled, y, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stopping])


weather_score = model.predict(X_scaled)
weather_score = MinMaxScaler((0, 100)).fit_transform(weather_score).flatten()

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(f"MAE: {mae:.2f}")
print(f"RMSE: {rmse:.2f}")
print(f"R²: {r2:.3f}")

"""## Light GBM

"""

import pandas as pd
import numpy as np
from lightgbm import LGBMRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import shap
from lightgbm import early_stopping, log_evaluation

df['FlightDate'] = pd.to_datetime(df['FlightDate'])
df['hour'] = df['CRSDepTime'] // 100
df['day_of_week'] = df['FlightDate'].dt.weekday
df['month'] = df['FlightDate'].dt.month


feature_cols = ['temperature_C','dew_point_C','humidity_percent',
                'precipitation_mm','snow_mm','wind_speed_kmh','pressure_hPa',
                'hour','day_of_week','month', 'wind_direction_deg']
X = df[feature_cols]
y = df['WeatherDelay']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LGBMRegressor(objective="quantile", alpha=0.9)


model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    eval_metric='rmse',
    callbacks=[early_stopping(stopping_rounds=50), log_evaluation(50)]
)


from sklearn.metrics import mean_squared_error
import numpy as np

y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
print(f"RMSE: {rmse:.2f}")

df_sample = (
    df.groupby("Origin_Airport")
      .apply(lambda g: g.sample(min(len(g), 2000000), random_state=42))
      .reset_index(drop=True)
)

explainer = shap.Explainer(model)
shap_values = explainer(df_sample[feature_cols])


global_importance = np.abs(shap_values.values).mean(axis=0)
importance_weights = pd.Series(global_importance, index=feature_cols)
importance_weights = importance_weights / importance_weights.sum()   # normalize to sum=1
importance_weights

airport_means = df.groupby("Origin_Airport")[weather_cols].mean()
airport_norm = (airport_means - airport_means.min()) / (airport_means.max() - airport_means.min())
airport_norm = airport_norm.fillna(0)

weather_weights = importance_weights[weather_cols]


airport_means["weather_score"] = (airport_norm * weather_weights).sum(axis=1)

# scale 0–100
airport_means["weather_score"] = 100 * airport_means["weather_score"] / airport_means["weather_score"].max()

final_scores = airport_means["weather_score"].sort_values(ascending=False)

print(final_scores)

import pandas as pd
import numpy as np


airport_data = airport_means[weather_cols].copy()


airport_data_norm = (airport_data - airport_data.min()) / (airport_data.max() - airport_data.min())
airport_data_norm.columns = [c + "_norm" for c in airport_data_norm.columns]


weather_weights = importance_weights[weather_cols]
weather_weights.name = "shap_weight"


plot_df = pd.concat([airport_data, airport_data_norm], axis=1)
plot_df["weather_score"] = airport_means["weather_score"]

plot_df

plot_df.to_csv("Final_Scores.csv")

import seaborn as sns
import matplotlib.pyplot as plt

def plot_feature_kde(feature):
    plt.figure(figsize=(10,6))


    sns.kdeplot(
        data=plot_df,
        x=feature,
        fill=True,
        alpha=0.4,
        linewidth=2
    )


    for airport, value in plot_df[feature].items():
        plt.scatter(value, 0, s=80, label=airport)

    plt.title(f"KDE Distribution of {feature} Across Major Airports")
    plt.xlabel(feature)
    plt.ylabel("Density")
    plt.grid(True)
    plt.show()



